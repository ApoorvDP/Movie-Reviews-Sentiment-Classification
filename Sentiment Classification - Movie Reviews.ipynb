{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification - Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Apoorv Pandey*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie reviews are a crucial aspect of sensitizing an audience towards a movie. They provide people with multiple perspectives and allow people to decide whether to watch a movie. Movie reviews are far more personalized than statistical ratings or scores. They embody the opinion of the reviewer, and are highly subjective in nature. A crucial characteristic of the reviews is their *sentiment*, or **overall opinion** towards the subject matter.\n",
    "\n",
    "This notebook implements a classifier approach to evaluating the sentiment of a movie review. The training data set is used to compute the weighted sentiment of all the words. The weighted sentiments of words are the fractions when the words were used within a review with a positive or a negative sentiment. They are computed by performing a weighted sum for each and every occurence of the words across the training data.\n",
    "\n",
    "The weighted sum is required because the same word can be used to express both a positive or a negative sentiment, depending on the context. A weighted sum, which is the weighted sentiment, can be used to glean the likelihood of the word's existence contributing to the direction of sentiment of the movoe review.\n",
    "\n",
    "The overall sentiment of reviews in the testing data are formulated as a sum of the weighted sentiments of the words present in the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions created in this notebook are:\n",
    "* `simplify(doc)`: Simplifies the input, and reduces simple text without special characters or whitespaces\n",
    "* `get_words(sentence)`: Returns a list of words for the input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(doc):\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A).lower().strip() # Remove special characters, whitespaces and make lower case\n",
    "    tokens = nltk.WordPunctTokenizer().tokenize(doc) # Tokenize\n",
    "    filtered_tokens = [token for token in tokens if token not in nltk.corpus.stopwords.words('english')] # Remove stopwords\n",
    "    doc = ' '.join(filtered_tokens) # Re-create document from filtered tokens\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(sentence):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(x) for x in simplify(sentence).split()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = open('training_set.csv', 'r') # Training data\n",
    "train.readline() # Read and remove header row\n",
    "word_sentiment = {} # Dictionary stores sentiment weight of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train:\n",
    "    sentiment, line = data.split(',')\n",
    "    words = get_words(line)\n",
    "    for word in words:\n",
    "        try: # Increment weight of the word by 1 if positive, decrement weight by 1 if negative\n",
    "            word_sentiment[word][0] = word_sentiment[word][0] + 1 if int(sentiment) == 1 else word_sentiment[word][0] - 1\n",
    "        except: # If word doesn't exist, create new entry in dictionary\n",
    "            word_sentiment[word] = [1, 0] if int(sentiment) == 1 else [-1, 0]\n",
    "        finally: # Increment number of occurences of the word; used later to compute the weighted sum instead of just sum\n",
    "            word_sentiment[word][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_weighted_sentiment = {word: word_sentiment[word][0] / word_sentiment[word][1] for word in word_sentiment.keys()}\n",
    "# Weighted sum of the sentiment of each word (divide weight of the word by number of occurences of the word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = open('test_set.csv', 'r') # Testing data\n",
    "test.readline() # Read and remove header row\n",
    "output = open('prediction_file.csv', 'a') # Output file (testing data with predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test:\n",
    "    sentiment = 0\n",
    "    words = get_words(data)\n",
    "    for word in words:\n",
    "        try:\n",
    "            sentiment += word_weighted_sentiment[word] # Compute sum of weighted sentiments of the words in the review\n",
    "        except:\n",
    "            sentiment += 0 # MISSING WORDS (words in testing data but not training data) ARE GIVEN SENTIMENT OF 0\n",
    "    if sentiment >= 0:\n",
    "        output.write('1,' + data + '\\n')\n",
    "    else:\n",
    "        output.write('0,' + data + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.close()\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the predictions may be observed in `prediction_file.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Training and testing datasets](https://inclass.kaggle.com/c/cs6998/data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
